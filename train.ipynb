{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una implementación de una máquina de aprendizaje extremo.\n",
    "Sobre los datos, basados en el dataset \"Facial expresión recognition challenge\" disponible en https://www.kaggle.com/datasets/debanga/facial-expression-recognition-challenge a través de una VQ-VAE se obtienen las matrices $x$ que contienen los índices de los embeddings a los que la imagen fue asociada en el espacio latente. La idea esa usar esas matrices para determinar si existe una correlación entre los índices de los embeddings seleccionados y la emoción a la que pertenece la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0hKB4kKbbTJ"
   },
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas: \n",
    "1. Los datos estaban muy desbalanceados.\n",
    "2. Los datos de entrenamiento y prueba que aquí se usan se obtuvieron de balancear el conjunto y separar en 80 - 20. Se hizo de esta forma para poder hacer una comparación con el mismo conjunto de datos en todos los modelos y que así no hubiera ninguna influencia sobre los datos de entrenamiento y prueba que le pudiera tocar a cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cV5gD8JcV2i"
   },
   "source": [
    "# Para el perceptrón.\n",
    "Se ajustó un MLP para usarlo como baseline en las comparativas de los resultados contra el ELM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "1VwXJ4xPW7O_",
    "outputId": "b5a0c77e-16ad-4d0d-b898-6b17a9231c3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m18,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,127</span> (113.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,127\u001b[0m (113.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,127</span> (113.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,127\u001b[0m (113.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modelo para el perceptrón\n",
    "\n",
    "model_perceptron = Sequential([\n",
    "    Input(shape=(144,)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model_perceptron.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_perceptron.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7zSMIBZVZLlb"
   },
   "outputs": [],
   "source": [
    "# checkpoint para el perceptrón\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model_perceptron.keras',\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             mode='max',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lShWehfVcBGV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m380/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.2413 - loss: 1.8574\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25029, saving model to best_model_perceptron.keras\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2425 - loss: 1.8526 - val_accuracy: 0.2503 - val_loss: 1.8155\n",
      "Epoch 2/30\n",
      "\u001b[1m433/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.2505 - loss: 1.8105\n",
      "Epoch 2: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.2505 - loss: 1.8105 - val_accuracy: 0.2503 - val_loss: 1.8196\n",
      "Epoch 3/30\n",
      "\u001b[1m417/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.2519 - loss: 1.8065\n",
      "Epoch 3: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2519 - loss: 1.8068 - val_accuracy: 0.2503 - val_loss: 1.8162\n",
      "Epoch 4/30\n",
      "\u001b[1m393/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.2526 - loss: 1.8074\n",
      "Epoch 4: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2524 - loss: 1.8077 - val_accuracy: 0.2503 - val_loss: 1.8161\n",
      "Epoch 5/30\n",
      "\u001b[1m419/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.2507 - loss: 1.8130\n",
      "Epoch 5: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.2508 - loss: 1.8129 - val_accuracy: 0.2503 - val_loss: 1.8179\n",
      "Epoch 6/30\n",
      "\u001b[1m412/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.2479 - loss: 1.8130\n",
      "Epoch 6: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2482 - loss: 1.8128 - val_accuracy: 0.2503 - val_loss: 1.8166\n",
      "Epoch 7/30\n",
      "\u001b[1m417/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.2555 - loss: 1.8077\n",
      "Epoch 7: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2553 - loss: 1.8078 - val_accuracy: 0.2503 - val_loss: 1.8178\n",
      "Epoch 8/30\n",
      "\u001b[1m406/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.2448 - loss: 1.8115\n",
      "Epoch 8: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2453 - loss: 1.8114 - val_accuracy: 0.2503 - val_loss: 1.8169\n",
      "Epoch 9/30\n",
      "\u001b[1m424/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.2466 - loss: 1.8155\n",
      "Epoch 9: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2468 - loss: 1.8153 - val_accuracy: 0.2503 - val_loss: 1.8180\n",
      "Epoch 10/30\n",
      "\u001b[1m428/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2516 - loss: 1.8126\n",
      "Epoch 10: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2516 - loss: 1.8125 - val_accuracy: 0.2503 - val_loss: 1.8156\n",
      "Epoch 11/30\n",
      "\u001b[1m417/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.2525 - loss: 1.8110\n",
      "Epoch 11: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2524 - loss: 1.8109 - val_accuracy: 0.2503 - val_loss: 1.8162\n",
      "Epoch 12/30\n",
      "\u001b[1m426/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.2528 - loss: 1.8083\n",
      "Epoch 12: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.2527 - loss: 1.8083 - val_accuracy: 0.2503 - val_loss: 1.8170\n",
      "Epoch 13/30\n",
      "\u001b[1m418/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.2495 - loss: 1.8121\n",
      "Epoch 13: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2497 - loss: 1.8120 - val_accuracy: 0.2503 - val_loss: 1.8168\n",
      "Epoch 14/30\n",
      "\u001b[1m420/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.2512 - loss: 1.8103\n",
      "Epoch 14: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.2512 - loss: 1.8103 - val_accuracy: 0.2503 - val_loss: 1.8159\n",
      "Epoch 15/30\n",
      "\u001b[1m419/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.2547 - loss: 1.8093\n",
      "Epoch 15: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2546 - loss: 1.8093 - val_accuracy: 0.2503 - val_loss: 1.8171\n",
      "Epoch 16/30\n",
      "\u001b[1m423/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.2487 - loss: 1.8123\n",
      "Epoch 16: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.2488 - loss: 1.8122 - val_accuracy: 0.2503 - val_loss: 1.8178\n",
      "Epoch 17/30\n",
      "\u001b[1m406/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.2491 - loss: 1.8136\n",
      "Epoch 17: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2492 - loss: 1.8133 - val_accuracy: 0.2503 - val_loss: 1.8171\n",
      "Epoch 18/30\n",
      "\u001b[1m429/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.2515 - loss: 1.8102\n",
      "Epoch 18: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2515 - loss: 1.8102 - val_accuracy: 0.2503 - val_loss: 1.8169\n",
      "Epoch 19/30\n",
      "\u001b[1m407/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.2523 - loss: 1.8104\n",
      "Epoch 19: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2523 - loss: 1.8103 - val_accuracy: 0.2503 - val_loss: 1.8157\n",
      "Epoch 20/30\n",
      "\u001b[1m405/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.2526 - loss: 1.8105\n",
      "Epoch 20: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2525 - loss: 1.8104 - val_accuracy: 0.2503 - val_loss: 1.8156\n",
      "Epoch 21/30\n",
      "\u001b[1m417/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.2503 - loss: 1.8088\n",
      "Epoch 21: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2504 - loss: 1.8089 - val_accuracy: 0.2503 - val_loss: 1.8162\n",
      "Epoch 22/30\n",
      "\u001b[1m399/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.2496 - loss: 1.8098\n",
      "Epoch 22: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2499 - loss: 1.8098 - val_accuracy: 0.2503 - val_loss: 1.8162\n",
      "Epoch 23/30\n",
      "\u001b[1m415/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.2505 - loss: 1.8090\n",
      "Epoch 23: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2505 - loss: 1.8090 - val_accuracy: 0.2503 - val_loss: 1.8168\n",
      "Epoch 24/30\n",
      "\u001b[1m436/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.2544 - loss: 1.8076\n",
      "Epoch 24: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.2544 - loss: 1.8076 - val_accuracy: 0.2503 - val_loss: 1.8157\n",
      "Epoch 25/30\n",
      "\u001b[1m398/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.2566 - loss: 1.8051\n",
      "Epoch 25: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2562 - loss: 1.8055 - val_accuracy: 0.2503 - val_loss: 1.8170\n",
      "Epoch 26/30\n",
      "\u001b[1m374/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.2511 - loss: 1.8102\n",
      "Epoch 26: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.2512 - loss: 1.8102 - val_accuracy: 0.2503 - val_loss: 1.8184\n",
      "Epoch 27/30\n",
      "\u001b[1m384/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.2585 - loss: 1.8064\n",
      "Epoch 27: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.2576 - loss: 1.8068 - val_accuracy: 0.2503 - val_loss: 1.8166\n",
      "Epoch 28/30\n",
      "\u001b[1m382/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.2593 - loss: 1.8040\n",
      "Epoch 28: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.2584 - loss: 1.8047 - val_accuracy: 0.2503 - val_loss: 1.8159\n",
      "Epoch 29/30\n",
      "\u001b[1m422/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.2541 - loss: 1.8090\n",
      "Epoch 29: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2540 - loss: 1.8090 - val_accuracy: 0.2503 - val_loss: 1.8155\n",
      "Epoch 30/30\n",
      "\u001b[1m412/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.2503 - loss: 1.8102\n",
      "Epoch 30: val_accuracy did not improve from 0.25029\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2504 - loss: 1.8101 - val_accuracy: 0.2503 - val_loss: 1.8155\n"
     ]
    }
   ],
   "source": [
    "history = model_perceptron.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el ELM con pesos aleatorios no binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elm(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_neurons=1000, regressor=None):\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def fit(self, X, y, binary_weights = False):\n",
    "        # Dependiendo de la selección de pesos binarios, se eligen pesos aleatorios o no\n",
    "        input_size = X.shape[1]\n",
    "\n",
    "        if binary_weights:\n",
    "            self.input_weights = np.random.choice([-1, 1], size=(input_size, self.n_hidden_neurons))\n",
    "            self.biases = np.random.choice([-1, 1], size=self.n_hidden_neurons)\n",
    "        else:\n",
    "            self.input_weights = np.random.randn(input_size, self.n_hidden_neurons)\n",
    "            self.biases = np.random.randn(self.n_hidden_neurons)\n",
    "        \n",
    "        # Salida de la capa oculta\n",
    "        H = self._sigmoid(np.dot(X, self.input_weights) + self.biases)\n",
    "        \n",
    "        # Regresión usando regularización si se especifica\n",
    "        self.regressor.fit(H, y)\n",
    "\n",
    "        # Calcular las predicciones sobre el conjunto de entrenamiento\n",
    "        y_pred_train = self.predict(X)\n",
    "        y_true_labels = np.argmax(y, axis=1)\n",
    "        y_pred_labels = np.argmax(y_pred_train, axis=1)\n",
    "        \n",
    "        accuracy_train = accuracy_score(y_true_labels, y_pred_labels)\n",
    "        print(f\"Accuracy en el conjunto de entrenamiento: {accuracy_train:.4f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        H = self._sigmoid(np.dot(X, self.input_weights) + self.biases)\n",
    "        return self.regressor.predict(H)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        # pa guardar el modelo\n",
    "        model_data = {\n",
    "            'input_weights': self.input_weights,\n",
    "            'biases': self.biases,\n",
    "            'regressor': self.regressor\n",
    "        }\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "    \n",
    "    def load(self, filename):\n",
    "        # pa cargar el modelo\n",
    "        with open(filename, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.input_weights = model_data['input_weights']\n",
    "        self.biases = model_data['biases']\n",
    "        self.regressor = model_data['regressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para el caso del ELM con pesos no binarios y distintos tipos de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = StandardScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.3131\n"
     ]
    }
   ],
   "source": [
    "# Sin regularización\n",
    "elm_no_reg = elm(n_hidden_neurons=1000, regressor=Ridge(alpha=0.0))\n",
    "elm_no_reg.fit(x_train_scaled, y_train)\n",
    "elm_no_reg.save('elm_no_reg.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un accuracy aún más alto que con el perceptrón multicapa. \n",
    "### Con regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.3150\n"
     ]
    }
   ],
   "source": [
    "elm_ridge = elm(n_hidden_neurons=1000, regressor=Ridge(alpha=1.0)) \n",
    "elm_ridge.fit(x_train_scaled, y_train)\n",
    "elm_ridge.save('elm_ridge.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene una mejor cara que sin regularización.\n",
    "### Con regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.2517\n"
     ]
    }
   ],
   "source": [
    "elm_lasso = elm(n_hidden_neurons=1000, regressor=Lasso(alpha=0.01))  \n",
    "elm_lasso.fit(x_train_scaled, y_train)\n",
    "elm_lasso.save('elm_lasso.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con Lasso parece tener un desempeño similar al perceptrón multicapa.\n",
    "### Con regularización Elastic-net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.2517\n"
     ]
    }
   ],
   "source": [
    "elm_elastic = elm(n_hidden_neurons=1000, regressor=ElasticNet(alpha=0.01, l1_ratio=0.5))  \n",
    "elm_elastic.fit(x_train_scaled, y_train)\n",
    "elm_elastic.save('elm_elastic.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora con pesos binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.3157\n"
     ]
    }
   ],
   "source": [
    "elm_no_reg_bin = elm(n_hidden_neurons=1000, regressor=Ridge(alpha=0.0))\n",
    "elm_no_reg_bin.fit(x_train_scaled, y_train, binary_weights=True)\n",
    "elm_no_reg_bin.save('elm_no_reg_bin.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un poco mejor que su competencia con pesos continuos.\n",
    "### Regularización Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.3115\n"
     ]
    }
   ],
   "source": [
    "elm_ridge_bin = elm(n_hidden_neurons=1000, regressor=Ridge(alpha=1.0))\n",
    "elm_ridge_bin.fit(x_train_scaled, y_train, binary_weights=True)\n",
    "elm_ridge_bin.save('elm_ridge_bin.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la regularización parece no apoyar tanto.\n",
    "### Regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.2517\n"
     ]
    }
   ],
   "source": [
    "elm_lasso_bin = elm(n_hidden_neurons=1000, regressor=Lasso(alpha=0.01))\n",
    "elm_lasso_bin.fit(x_train_scaled, y_train, binary_weights=True)\n",
    "elm_lasso_bin.save('elm_lasso_bin.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas comparando con el perceptrón multicapa.\n",
    "### Regularización Elastic-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.2517\n"
     ]
    }
   ],
   "source": [
    "elm_elastic_bin = elm(n_hidden_neurons=1000, regressor=ElasticNet(alpha=0.01, l1_ratio=0.5))\n",
    "elm_elastic_bin.fit(x_train_scaled, y_train, binary_weights=True)\n",
    "elm_elastic_bin.save('elm_elastic_bin.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que, al igual que en el caso de valores continuos, las últimas dos regularizaciones se comportan muy similar."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
